{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nnAudio.Spectrogram import CQT1992v2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "BS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 64\n",
    "FOLD = 0\n",
    "qtransform_params={\"sr\": 2048, \"fmin\": 20, \"fmax\": 1024, \"hop_length\": 32, \"bins_per_octave\": 8}\n",
    "INPUT_PATH = Path(\"/home/trytolose/rinat/kaggle/grav_waves_detection/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, steps_per_epoch=150, mode='train'):\n",
    "        self.df = df\n",
    "        self.file_names = df['path'].values\n",
    "        self.wave_transform = CQT1992v2(**qtransform_params)\n",
    "        self.transform = transform\n",
    "        self.steps_per_epoch = steps_per_epoch*BS\n",
    "        self.mode = mode\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.mode=='train':\n",
    "            return self.steps_per_epoch\n",
    "        else:\n",
    "            return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_names[idx]\n",
    "        waves = np.load(file_path)\n",
    "        waves = np.hstack(waves)\n",
    "        waves = waves / np.max(waves)\n",
    "        return waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\"efficientnet_b0\", pretrained=pretrained, in_chans=1)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, 1)\n",
    "        self.cqt = CQT1992v2(**qtransform_params) #qtransform_params={\"sr\": 2048, \"fmin\": 20, \"fmax\": 1024, \"hop_length\": 32, \"bins_per_octave\": 8}\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cqt(x).unsqueeze(1)\n",
    "        x = nn.functional.interpolate(x, (256, 386))\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_PATH / \"sample_submission.csv\")\n",
    "\n",
    "files = list((INPUT_PATH / \"test\").rglob(\"*.npy\"))\n",
    "FILE_PATH_DICT = {x.stem: str(x) for x in files}\n",
    "df[\"path\"] = df[\"id\"].apply(lambda x: FILE_PATH_DICT[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_PATH / \"training_labels.csv\")\n",
    "\n",
    "files = list((INPUT_PATH / \"train\").rglob(\"*.npy\"))\n",
    "FILE_PATH_DICT = {x.stem: str(x) for x in files}\n",
    "df[\"path\"] = df[\"id\"].apply(lambda x: FILE_PATH_DICT[x])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
    "df[\"fold\"] = -1\n",
    "for f, (train_ids, val_ids) in enumerate(skf.split(df.index, y=df[\"target\"])):\n",
    "    df.loc[val_ids, \"fold\"] = f\n",
    "    \n",
    "df = df[df[\"fold\"] == FOLD].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = TrainDataset(df, mode=\"val\")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, shuffle=False, num_workers=12, batch_size=BS*2, pin_memory=False\n",
    ")\n",
    "\n",
    "model = CustomModel(pretrained=False)\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(\"baseline_f0.pt\"))\n",
    "\n",
    "val_pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(val_loader, ncols=50):\n",
    "        x = x.cuda().float().unsqueeze(1)\n",
    "        pred = model(x)\n",
    "        pred = pred.sigmoid().cpu().data.numpy()\n",
    "        val_pred.append(pred)\n",
    "\n",
    "\n",
    "    val_pred = np.concatenate(val_pred).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_pred'] = val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"path\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c g2net-gravitational-wave-detection -f submission.csv -m \"public baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-shareware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_fp=df[df['target']==0].sort_values(\"target_pred\", ascending=False)[:10]\n",
    "df_top_fp.to_csv(\"top_10_fp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df.sort_values(\"target_pred\")[:10].copy()\n",
    "df_max = df.sort_values(\"target_pred\", ascending=False)[:10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_max, df_min], ignore_index=True)\n",
    "df_total.to_csv(\"top_min_max.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-special",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-workplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
