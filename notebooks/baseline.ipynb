{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from pickle import dump, load\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-liver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, LambdaLR\n",
    "from sklearn import metrics\n",
    "from collections import deque\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "swedish-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = Path(\"/hdd2/kaggle/g2net/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-nebraska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000e74ad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001f4945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000661522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00007a006a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a38978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target\n",
       "0  00000e74ad       1\n",
       "1  00001f4945       0\n",
       "2  0000661522       0\n",
       "3  00007a006a       0\n",
       "4  0000a38978       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH / \"training_labels.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "above-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list((INPUT_PATH / \"train\").rglob(\"*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dimensional-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [15:20<00:00, 108.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(69)\n",
    "# sample = np.random.choice(files, 100000, replace=False)\n",
    "# sample_ar = []\n",
    "\n",
    "# for s in tqdm(sample):\n",
    "#     sample_ar.append(np.load(s).T)\n",
    "# sample_ar = np.concatenate(sample_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "express-giant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(feature_range=(-1, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# scaler.fit(sample_ar)\n",
    "# sample_ar = scaler.fit_transform(sample_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "split-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reasonable-excerpt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = np.load(\"/hdd2/kaggle/g2net/input/train/0/0/0/00000e74ad.npy\")\n",
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "necessary-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wave_Block_true(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,dilation_rates):\n",
    "        super(Wave_Block_true,self).__init__()\n",
    "        self.num_rates = dilation_rates\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.dil_convs = nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(nn.Conv1d(in_channels,out_channels,kernel_size=1))\n",
    "        dilation_rates = [2**i for i in range(dilation_rates)]\n",
    "        for dilation_rate in dilation_rates:\n",
    "            self.dil_convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=3,padding=dilation_rate, dilation=dilation_rate))\n",
    "            self.filter_convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=3,padding=1))\n",
    "            self.gate_convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=3,padding=1))\n",
    "            self.convs.append(nn.Conv1d(out_channels,out_channels,kernel_size=1))\n",
    "            \n",
    "        self.end_block = nn.Sequential(nn.ReLU(), nn.Conv1d(out_channels,out_channels,kernel_size=1), nn.ReLU(), nn.Conv1d(out_channels,out_channels,kernel_size=1))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = self.convs[0](x)\n",
    "#         res = x\n",
    "        skip = 0\n",
    "        for i in range(self.num_rates):\n",
    "            \n",
    "            res = x\n",
    "            x = self.dil_convs[i](x)\n",
    "            x = torch.mul(torch.tanh(self.filter_convs[i](x)), torch.sigmoid(self.gate_convs[i](x))) \n",
    "            x = self.convs[i+1](x)\n",
    "            skip = skip + x\n",
    "            #x += res\n",
    "            x = x + res\n",
    "        \n",
    "        x = self.end_block(skip)\n",
    "        return x\n",
    "\n",
    "class Andrewnet_v3_true(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.first_conv = nn.Sequential(nn.Conv1d(in_channels,64,7,padding=3), nn.BatchNorm1d(64), nn.ReLU())\n",
    "        self.waveblock_1 = nn.Sequential(Wave_Block_true(64, 16, 12), nn.BatchNorm1d(16))\n",
    "        self.waveblock_2 = nn.Sequential(Wave_Block_true(16, 32, 8), nn.BatchNorm1d(32))\n",
    "        self.waveblock_3 = nn.Sequential(Wave_Block_true(32, 64, 4), nn.BatchNorm1d(64))\n",
    "        self.waveblock_4 = nn.Sequential(Wave_Block_true(64, 128, 1), nn.BatchNorm1d(128))\n",
    "        self.waveblock_5 = nn.Sequential( \n",
    "                                        nn.Conv1d(128,128,7,padding=3), \n",
    "                                        nn.BatchNorm1d(128), \n",
    "                                        nn.ReLU())\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first_conv(x)\n",
    "        x = self.waveblock_1(x)\n",
    "        x = self.waveblock_2(x)\n",
    "        x = self.waveblock_3(x)\n",
    "        x = self.waveblock_4(x)\n",
    "        x = self.waveblock_5(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x.view(-1, 128))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cellular-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor(x_sample).unsqueeze(0).float()\n",
    "# model = Andrewnet_v3_true(3)\n",
    "# pred = model(x)\n",
    "# print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brown-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000e74ad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001f4945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000661522</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00007a006a</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a38978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559995</th>\n",
       "      <td>ffff9a5645</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559996</th>\n",
       "      <td>ffffab0c27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559997</th>\n",
       "      <td>ffffcf161a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559998</th>\n",
       "      <td>ffffd2c403</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559999</th>\n",
       "      <td>fffff2180b</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  target  fold\n",
       "0       00000e74ad       1     0\n",
       "1       00001f4945       0     0\n",
       "2       0000661522       0     4\n",
       "3       00007a006a       0     3\n",
       "4       0000a38978       1     0\n",
       "...            ...     ...   ...\n",
       "559995  ffff9a5645       1     0\n",
       "559996  ffffab0c27       0     2\n",
       "559997  ffffcf161a       1     2\n",
       "559998  ffffd2c403       0     4\n",
       "559999  fffff2180b       0     2\n",
       "\n",
       "[560000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broken-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH_DICT = {x.stem: str(x) for x in files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deadly-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=69)\n",
    "df['fold'] = -1\n",
    "for f, (train_ids, val_ids) in enumerate(skf.split(df.index, y=df['target'])):\n",
    "    df.loc[val_ids, 'fold'] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "least-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"path\"] = df[\"id\"].apply(lambda x: FILE_PATH_DICT[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "every-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, df, scaler):\n",
    "        self.df = df\n",
    "        self.scaler = scaler\n",
    "        \n",
    "    def __len__(self):     \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.loc[idx, \"path\"]\n",
    "        target = float(self.df.loc[idx, \"target\"])\n",
    "        x = self.scaler.transform(np.load(path).T).T\n",
    "        return x, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "transsexual-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 16/16 [00:03<00:00,  4.26it/s]\n",
      "100%|█████████████| 16/16 [00:01<00:00,  9.38it/s]\n",
      "  0%|                                          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000; val_loss: 0.69408; roc: 0.49936 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 16/16 [00:03<00:00,  4.11it/s]\n",
      "100%|█████████████| 16/16 [00:01<00:00,  9.34it/s]\n",
      "  0%|                                          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001; val_loss: 0.69367; roc: 0.50427 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████▉                   | 7/16 [00:02<00:02,  3.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2370b58ae18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/audio/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BS = 64\n",
    "FOLD = 0\n",
    "\n",
    "scaler = load(open('scaler.pkl', 'rb'))\n",
    "train_ds = SignalDataset(df[df['fold']!=FOLD].reset_index(drop=True)[:1000], scaler)\n",
    "val_ds = SignalDataset(df[df['fold']==FOLD].reset_index(drop=True)[:1000], scaler)\n",
    "\n",
    "train_loader = utils.DataLoader(train_ds, shuffle=True, num_workers=11, batch_size=BS, pin_memory=True)\n",
    "val_loader = utils.DataLoader(val_ds, shuffle=False, num_workers=11, batch_size=BS, pin_memory=True)\n",
    "\n",
    "\n",
    "model = Andrewnet_v3_true(3)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', verbose=True, patience=5, factor=0.5, eps=1e-12)\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_models = deque(maxlen=5)\n",
    "for e in range(100):\n",
    "\n",
    "    # Training:\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in tqdm(train_loader, ncols = 70):   \n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda().float()\n",
    "        y = y.cuda().float().unsqueeze(1)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    val_loss = []\n",
    "\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader, ncols=50):\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().float().unsqueeze(1)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            pred = pred.sigmoid().cpu().data.numpy()\n",
    "            val_pred.append(pred)\n",
    "            val_true.append(y.cpu().numpy())\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    \n",
    "    val_true = np.concatenate(val_true).reshape(-1,)\n",
    "    val_pred = np.concatenate(val_pred).reshape(-1,)\n",
    "    \n",
    "    final_score = metrics.roc_auc_score(val_true, val_pred)\n",
    "        \n",
    "    # print(f'Epoch: {e:03d}; lr: {lr:.06f}; train_loss: {np.mean(train_loss):.05f}; val_loss: {val_loss:.05f}; ', end='')\n",
    "    print(f'Epoch: {e:03d}; train_loss: {np.mean(train_loss):.05f} val_loss: {val_loss:.05f}; roc: {final_score:.5f}', end=' ')\n",
    " \n",
    "    if final_score > best_score:\n",
    "        best_score = final_score\n",
    "        torch.save(model.state_dict(), f\"baseline_f0.pt\")        \n",
    "    else:\n",
    "        print()\n",
    "\n",
    "    # print(metrics.classification_report(val_true, val_pred))\n",
    "        \n",
    "    scheduler.step(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-summary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-midnight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "distributed-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        \n",
    "    def __len__(self):     \n",
    "        return 250#len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rand_id = np.random.randint(len(self.df), size=1)[0]\n",
    "        return df.loc[rand_id, \"value\"]\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"value\"] = np.arange(500)\n",
    "\n",
    "    \n",
    "train_loader = utils.DataLoader(SignalDataset(df), shuffle=True, num_workers=10, batch_size=10, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "exciting-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = list(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "incredible-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([272, 394, 436, 385, 134,  98, 118, 133, 371, 295]),\n",
       " tensor([ 17, 398, 205, 131, 145, 108, 417,  34, 409, 195]),\n",
       " tensor([328, 168, 225, 149,  42, 364, 492, 188, 426, 431]),\n",
       " tensor([147, 352,  79, 201,  93, 447, 138, 162,  30, 190]),\n",
       " tensor([376, 400,  97,  61, 325,  65, 438, 376, 105, 343]),\n",
       " tensor([ 15, 444, 324,  53, 445, 477, 329, 392, 432, 103]),\n",
       " tensor([427, 124, 318, 320, 319, 109, 341, 112, 110, 420]),\n",
       " tensor([ 89, 443, 142, 377,  65,  14,  58, 236,  78, 330]),\n",
       " tensor([ 84, 220, 353, 351, 171, 426, 492, 430, 271, 412]),\n",
       " tensor([193, 363, 208, 456, 163,  36, 212, 275, 474, 108]),\n",
       " tensor([162,  15,  35, 273,  48, 171,  10, 498, 235, 157]),\n",
       " tensor([346, 365, 484, 263, 281, 377, 172, 473, 161, 369]),\n",
       " tensor([135, 470,  78,  86, 326, 288, 312, 300, 245,  49]),\n",
       " tensor([  7, 111, 183, 274,  43, 200, 105, 295, 167, 343]),\n",
       " tensor([138,  26, 388, 186, 311, 183, 128, 303,  71, 200]),\n",
       " tensor([234,   0, 219, 474, 230, 328, 168, 220, 236, 340]),\n",
       " tensor([114, 221, 447, 116, 245, 249, 310, 165, 143, 193]),\n",
       " tensor([334,  28,   2,  70, 424, 236, 108, 127, 254, 380]),\n",
       " tensor([495, 334, 431, 177, 418, 267,  46, 150, 112, 198]),\n",
       " tensor([361, 303, 254, 397, 165, 460, 337, 319, 224, 314]),\n",
       " tensor([159,  82, 326, 320, 239, 241, 441, 317, 256, 350]),\n",
       " tensor([ 76, 236, 435, 402, 450,   1,  31, 281, 382,  62]),\n",
       " tensor([ 91, 238,  51,   6,  68,  51,  40,  49, 450, 328]),\n",
       " tensor([ 13, 232, 157, 495,  58, 219, 458, 333,  51, 331]),\n",
       " tensor([253, 296, 127, 297, 158, 423, 326, 322, 484, 100])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-involvement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
